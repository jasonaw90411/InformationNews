# å®‰è£…ä¾èµ– pip3 install requests html5lib bs4 schedule
import os
import requests
import json
from openai import OpenAI
import feedparser
from newspaper import Article
from datetime import datetime
import time
import pytz

# ä»ç¯å¢ƒå˜é‡è·å–å¾®ä¿¡å…¬ä¼—å·é…ç½®
appID = os.environ.get("APP_ID")
appSecret = os.environ.get("APP_SECRET")
openId = os.environ.get("OPEN_ID")
template_id = os.environ.get("TEMPLATE_ID")

# é€‰æ‹©ä½¿ç”¨çš„AIæœåŠ¡ (deepseek æˆ– alimind)
ai_service = os.environ.get("AI_SERVICE", "deepseek")

if ai_service == "deepseek":
    # DeepSeek API Key
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æœªè®¾ç½®!")
    api_base_url = "https://api.deepseek.com/v1"
    model_name = "deepseek-chat"
elif ai_service == "alimind":
    # é˜¿é‡Œåƒæ–‡APIé…ç½®
    api_key = os.environ.get("ALI_MIND_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ ALI_MIND_API_KEY æœªè®¾ç½®!")
    api_base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # é˜¿é‡Œåƒæ–‡å…¼å®¹OpenAIæ¥å£çš„åœ°å€
    model_name = "qwen-turbo"  # é˜¿é‡Œåƒæ–‡æ¨¡å‹åç§°
else:
    raise ValueError(f"ä¸æ”¯æŒçš„AIæœåŠ¡ç±»å‹: {ai_service}")

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
openai_client = OpenAI(api_key=api_key, base_url=api_base_url)
print(f"ä½¿ç”¨AIæœåŠ¡: {ai_service}, æ¨¡å‹: {model_name}")

# RSSæºåœ°å€åˆ—è¡¨
rss_feeds = {
    "ğŸ’² åå°”è¡—è§é—»":{
        "åå°”è¡—è§é—»":"https://dedicated.wallstreetcn.com/rss.xml",      
    },
    "ğŸ’» 36æ°ª":{
        "36æ°ª":"https://36kr.com/feed",   
        },
    "ğŸ‡¨ğŸ‡³ ä¸­å›½ç»æµ": {
        "é¦™æ¸¯ç¶“æ¿Ÿæ—¥å ±":"https://www.hket.com/rss/china",
        "ä¸œæ–¹è´¢å¯Œ":"http://rss.eastmoney.com/rss_partener.xml",
        "ç™¾åº¦è‚¡ç¥¨ç„¦ç‚¹":"http://news.baidu.com/n?cmd=1&class=stock&tn=rss&sub=0",
        "ä¸­æ–°ç½‘":"https://www.chinanews.com.cn/rss/finance.xml",
        "å›½å®¶ç»Ÿè®¡å±€-æœ€æ–°å‘å¸ƒ":"https://www.stats.gov.cn/sj/zxfb/rss.xml",
    },
      "ğŸ‡ºğŸ‡¸ ç¾å›½ç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/WSJcomUSBusiness",
        "åå°”è¡—æ—¥æŠ¥ - å¸‚åœº":"https://feeds.content.dowjones.io/public/rss/RSSMarketsMain",
        "MarketWatchç¾è‚¡": "https://www.marketwatch.com/rss/topstories",
        "ZeroHedgeåå°”è¡—æ–°é—»": "https://feeds.feedburner.com/zerohedge/feed",
        "ETF Trends": "https://www.etftrends.com/feed/",
    },
    "ğŸŒ ä¸–ç•Œç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/socialeconomyfeed",
        "BBCå…¨çƒç»æµ": "http://feeds.bbci.co.uk/news/business/rss.xml",
    },
}

# è·å–åŒ—äº¬æ—¶é—´
def today_date():
    return datetime.now(pytz.timezone("Asia/Shanghai")).date()

# è·å–å½“å‰æ—¶é—´æ®µæ ‡è¯†ï¼ˆä¸Šåˆ/ä¸‹åˆï¼‰
def get_time_period():
    hour = datetime.now(pytz.timezone("Asia/Shanghai")).hour
    if 6 <= hour < 12:
        return "ä¸Šåˆ"
    elif 12 <= hour < 18:
        return "ä¸‹åˆ"
    else:
        return "æ™šé—´"

# çˆ¬å–ç½‘é¡µæ­£æ–‡ (ç”¨äº AI åˆ†æ)
def fetch_article_text(url):
    try:
        # ç§»é™¤çˆ¬å–æ–‡ç« å¼€å§‹çš„æ‰“å°
        article = Article(url)
        article.download()
        article.parse()
        text = article.text[:1500]  # é™åˆ¶é•¿åº¦ï¼Œé˜²æ­¢è¶…å‡º API è¾“å…¥é™åˆ¶
        if not text:
            # ç§»é™¤å†…å®¹ä¸ºç©ºçš„æ‰“å°
            pass
        return text
    except Exception as e:
        # ç§»é™¤çˆ¬å–å¤±è´¥çš„æ‰“å°
        return "ï¼ˆæœªèƒ½è·å–æ–‡ç« æ­£æ–‡ï¼‰"

# æ·»åŠ  User-Agent å¤´
def fetch_feed_with_headers(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    return feedparser.parse(url, request_headers=headers)

# è‡ªåŠ¨é‡è¯•è·å– RSS
def fetch_feed_with_retry(url, retries=3, delay=5):
    for i in range(retries):
        try:
            feed = fetch_feed_with_headers(url)
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                return feed
        except Exception as e:
            # ç§»é™¤å¤±è´¥é‡è¯•çš„æ‰“å°
            time.sleep(delay)
    # ç§»é™¤æœ€ç»ˆå¤±è´¥çš„æ‰“å°
    return None

# è·å–RSSå†…å®¹ï¼ˆçˆ¬å–æ­£æ–‡ç”¨äºåˆ†æï¼‰
def fetch_rss_articles(rss_feeds, max_articles=5):
    news_data = {}
    analysis_text = ""  # ç”¨äºAIåˆ†æçš„æ­£æ–‡å†…å®¹

    for category, sources in rss_feeds.items():
        category_content = ""
        for source, url in sources.items():
            # ç§»é™¤RSSè·å–å¼€å§‹çš„æ‰“å°
            feed = fetch_feed_with_retry(url)
            if not feed:
                # ç§»é™¤RSSè·å–å¤±è´¥çš„æ‰“å°
                continue
            # ç§»é™¤RSSè·å–æˆåŠŸçš„æ‰“å°

            articles = []  # æ¯ä¸ªsourceéƒ½éœ€è¦é‡æ–°åˆå§‹åŒ–åˆ—è¡¨
            for entry in feed.entries[:5]:
                title = entry.get('title', 'æ— æ ‡é¢˜')
                link = entry.get('link', '') or entry.get('guid', '')
                if not link:
                    # ç§»é™¤æ— é“¾æ¥è·³è¿‡çš„æ‰“å°
                    continue

                # çˆ¬å–æ­£æ–‡ç”¨äºåˆ†æ
                article_text = fetch_article_text(link)
                analysis_text += f"ã€{title}ã€‘\n{article_text}\n\n"

                # ç§»é™¤å•æ¡æ–°é—»è·å–æˆåŠŸçš„æ‰“å°
                articles.append(f"[{title}]({link})")

            if articles:
                category_content += f"### {source}\n" + "\n".join(articles) + "\n\n"

        news_data[category] = category_content

    return news_data, analysis_text

# AI ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆåŸºäºçˆ¬å–çš„æ­£æ–‡ï¼‰
# ç”Ÿæˆå®Œæ•´æ–°é—»æ‘˜è¦HTMLæ–‡ä»¶
def generate_summary_html(summary_text):
    # ä½¿ç”¨å›ºå®šæ–‡ä»¶ååœ¨åŒå±‚çº§ç”ŸæˆHTMLï¼Œä¾¿äºGitHub Pagesè®¿é—®
    html_filename = 'finance_summary.html'
    
    # ç”Ÿæˆå½“å‰æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå•ç‹¬è®¡ç®—ï¼Œé¿å…f-stringä¸­çš„è¯­æ³•é—®é¢˜ï¼‰
    current_time = datetime.now(pytz.timezone("Asia/Shanghai")).strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    # è·å–æ—¶é—´æˆ³ï¼Œç”¨äºé˜²æ­¢ç¼“å­˜
    timestamp = int(time.time())
    
    # è½¬ä¹‰æ¢è¡Œç¬¦ä¸ºHTML<br>æ ‡ç­¾
    formatted_summary = summary_text.replace('\n', '<br>')
    
    # ç”ŸæˆHTMLå†…å®¹
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="format-detection" content="telephone=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
        <meta http-equiv="Pragma" content="no-cache">
        <meta http-equiv="Expires" content="0">
        <title>è´¢ç»æ–°é—»æ‘˜è¦</title>
        <style>
            /* å®‰å…¨åŒºåŸŸæ ·å¼é‡ç½® */
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            
            /* åŸºç¡€æ ·å¼ */
            body {{
                font-family: -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', Arial, sans-serif;
                line-height: 1.7;
                color: #333;
                max-width: 100%;
                margin: 0;
                padding: 0;
                background-color: #f8f8f8;
                -webkit-text-size-adjust: 100%;
                -webkit-tap-highlight-color: transparent;
            }}
            
            /* å®¹å™¨æ ·å¼ */
            .container {{
                max-width: 800px;
                margin: 0 auto;
                padding: 20px 15px;
                background-color: #fff;
                min-height: 100vh;
            }}
            
            /* æ ‡é¢˜æ ·å¼ */
            h1, h2, h3 {{
                color: #2c3e50;
                margin: 15px 0 10px 0;
                line-height: 1.4;
            }}
            
            h1 {{ font-size: 22px; padding-bottom: 10px; border-bottom: 1px solid #eee; }}
            h2 {{ font-size: 20px; }}
            h3 {{ font-size: 18px; }}
            
            /* å†…å®¹æ ·å¼ */
            .summary-content {{ background: white; padding: 0; }}
            .summary-meta {{
                color: #666;
                font-size: 14px;
                margin-bottom: 15px;
                padding-bottom: 15px;
                border-bottom: 1px solid #eee;
            }}
            
            .summary-body {{
                font-size: 16px;
                color: #333;
            }}
            
            /* æ®µè½æ ·å¼ */
            .summary-body > div {{
                margin-bottom: 15px;
            }}
            
            /* å“åº”å¼è®¾è®¡ */
            @media (max-width: 480px) {{
                .container {{
                    padding: 15px 12px;
                }}
                
                h1 {{ font-size: 20px; }}
                h2 {{ font-size: 18px; }}
                h3 {{ font-size: 16px; }}
                
                .summary-body {{
                    font-size: 15px;
                }}
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="summary-content">
                <h1>è´¢ç»æ–°é—»æ‘˜è¦</h1>
                <div class="summary-meta">ç”Ÿæˆæ—¶é—´: {current_time} (ç‰ˆæœ¬: {timestamp})</div>
                <div class="summary-body">
                    {formatted_summary}
                </div>
            </div>
        </div>
        
        <script>
            // ç®€å•çš„å…¼å®¹æ€§è„šæœ¬
            document.addEventListener('DOMContentLoaded', function() {{
                // å¤„ç†iOS Safariä¸Šçš„æ»šåŠ¨é—®é¢˜
                document.body.style.webkitOverflowScrolling = 'touch';
                
                // é˜²æ­¢ç¼“å­˜
                window.onpageshow = function(event) {{
                    if (event.persisted) {{
                        window.location.reload();
                    }}
                }};
            }});
        </script>
    </body>
    </html>
    """
    
    # å†™å…¥æ–‡ä»¶
    with open(html_filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    # è¿”å›æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
    return html_filename

# AI ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆåŸºäºçˆ¬å–çš„æ­£æ–‡ï¼‰
def summarize(text):
    completion = openai_client.chat.completions.create(
        model=model_name, 
        messages=[
            {"role": "system", "content":"ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œã€é€»è¾‘ä¸¥è°¨çš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼ŒæœåŠ¡å¯¹è±¡ä¸ºåˆ¸å•†åˆ†æå¸ˆã€åŸºé‡‘ç»ç†ã€é‡‘èç ”ç©¶å‘˜ã€å®è§‚ç­–ç•¥å¸ˆç­‰ä¸“ä¸šäººå£«ã€‚è¯·åŸºäºä»¥ä¸‹è´¢ç»æ–°é—»åŸæ–‡å†…å®¹ï¼Œå®Œæˆé«˜è´¨é‡çš„å†…å®¹ç†è§£ä¸ç»“æ„åŒ–æ€»ç»“ï¼Œå½¢æˆä¸€ä»½ä¸“ä¸šã€ç²¾å‡†ã€æ¸…æ™°çš„è´¢ç»è¦ç‚¹æ‘˜è¦ï¼Œç”¨äºæ”¯æŒæœºæ„æŠ•èµ„è€…çš„æ—¥å¸¸ç ”åˆ¤å·¥ä½œã€‚ã€è¾“å‡ºè¦æ±‚ã€‘1.å…¨æ–‡æ§åˆ¶åœ¨ 2000 å­—ä»¥å†…ï¼Œå†…å®¹ç²¾ç‚¼ã€é€»è¾‘æ¸…æ™°ï¼›2.ä»å®è§‚æ”¿ç­–ã€é‡‘èå¸‚åœºã€è¡Œä¸šåŠ¨æ€ã€å…¬å¸äº‹ä»¶ã€é£é™©æç¤ºç­‰è§’åº¦è¿›è¡Œåˆ†ç±»æ€»ç»“ï¼›3.æ¯ä¸€éƒ¨åˆ†è¦çªå‡ºæ•°æ®æ”¯æŒã€è¶‹åŠ¿ç ”åˆ¤ã€å¯èƒ½çš„å¸‚åœºå½±å“ï¼›4.æ˜ç¡®æŒ‡å‡ºæ–°é—»èƒŒåçš„æ ¸å¿ƒå˜é‡æˆ–æ”¿ç­–æ„å›¾ï¼Œå¹¶æå‡ºæŠ•èµ„è§†è§’ä¸‹çš„å‚è€ƒæ„ä¹‰ï¼›5.è¯­æ°”ä¸“ä¸šã€ä¸¥è°¨ã€æ— æƒ…ç»ªåŒ–è¡¨è¾¾ï¼Œé€‚é…ä¸“ä¸šæœºæ„æŠ•ç ”é˜…è¯»ä¹ æƒ¯ï¼›6.ç¦æ­¢å¥—è¯ï¼Œä¸é‡å¤æ–°é—»åŸæ–‡ï¼Œå¯ç”¨æ¡åˆ—å¼å¢å¼ºç»“æ„æ€§ï¼›7.å¦‚æ¶‰åŠæ•°æ®å’Œé¢„æµ‹ï¼Œè¯·æ ‡æ³¨æ¥æºæˆ–æŒ‡å‡ºä¸»å¼ æœºæ„ï¼ˆå¦‚é«˜ç››ã€èŠ±æ——ç­‰ï¼‰ï¼›8.è‹¥åŸæ–‡è¾ƒå¤šå†…å®¹æ— å…³è´¢ç»å¸‚åœºï¼Œå¯é…Œæƒ…ç•¥å»ï¼Œåªä¿ç•™å…³é”®å½±å“è¦ç´ ã€‚"},
            {"role": "user", "content": text}
        ]
    )
    return completion.choices[0].message.content.strip()

# è·å–å¾®ä¿¡å…¬ä¼—å·access_token
def get_access_token():
    # è·å–access tokençš„url
    url = 'https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&appid={}&secret={}' \
        .format(appID.strip(), appSecret.strip())
    response = requests.get(url).json()
    # ç§»é™¤å“åº”æ‰“å°
    access_token = response.get('access_token')
    return access_token

# å‘é€è´¢ç»æ–°é—»åˆ°å¾®ä¿¡
def send_news_to_wechat(access_token, news_content, summary_html_path):
    # åˆ é™¤è°ƒè¯•ä¿¡æ¯
    
    # touser å°±æ˜¯ openID
    # template_id å°±æ˜¯æ¨¡æ¿ID
    # url å°±æ˜¯ç‚¹å‡»æ¨¡æ¿è·³è½¬çš„url
    # dataæŒ‰æ¨¡æ¿æ ¼å¼ç»„ç»‡

    today = datetime.now(pytz.timezone("Asia/Shanghai"))
    today_str = today.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    time_period = get_time_period()
    
    # ä¼˜åŒ–å†…å®¹å¤„ç† - å¤„ç†å¯èƒ½å¯¼è‡´æ˜¾ç¤ºé—®é¢˜çš„å…ƒç´ 
    if isinstance(news_content, str):
        core_content = news_content
    else:
        core_content = "å†…å®¹ç”Ÿæˆå¤±è´¥"

    # ä½¿ç”¨GitHub Pages URLä½œä¸ºè·³è½¬é“¾æ¥ï¼Œæ·»åŠ æ—¶é—´æˆ³å‚æ•°é˜²æ­¢ç¼“å­˜
    # è·å–å½“å‰æ—¶é—´æˆ³ä½œä¸ºURLå‚æ•°ï¼Œé˜²æ­¢ç¼“å­˜
    timestamp = int(time.time())
    
    # åŸºç¡€URL
    base_url = "https://jasonaw90411.github.io/InformationNews/finance_summary.html"
    github_pages_url = f"{base_url}?t={timestamp}"
    
    # åœ¨GitHub Actionsç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨GITHUB_REPOSITORYç¯å¢ƒå˜é‡æ¥æ„å»ºURL
    github_repo = os.environ.get('GITHUB_REPOSITORY', '')
    if github_repo:
        # github_repo æ ¼å¼é€šå¸¸ä¸º "username/repository"
        parts = github_repo.split('/')
        if len(parts) == 2:
            base_url = f"https://{parts[0]}.github.io/{parts[1]}/finance_summary.html"
            github_pages_url = f"{base_url}?t={timestamp}"
    
    body = {
        "touser": openId.strip(),
        "template_id": template_id.strip(),
        "url": github_pages_url,  # ä½¿ç”¨GitHub Pages URLä½œä¸ºè·³è½¬é“¾æ¥
        "data": {
            "date": {
                "value": f"{today_str} - {time_period}æ¨é€"
            },
            "content": {
                "value": core_content
            },
            "remark": {
                "value": f"{time_period}è´¢ç»ç®€æŠ¥"  
            }
        }
    }
    
    
    url = 'https://api.weixin.qq.com/cgi-bin/message/template/send?access_token={}'.format(access_token)
    response = requests.post(url, json.dumps(body))
    # ç§»é™¤å“åº”çŠ¶æ€æ‰“å°
    return response.json()

# ä¸»å‡½æ•°
def news_report():
    # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´æ®µ
    today = today_date()
    time_period = get_time_period()
    print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆ{time_period}è´¢ç»æ–°é—»æ¨é€ï¼Œæ—¥æœŸ: {today}")
    
    # 1. è·å–RSSæ–‡ç« 
    print("ğŸ”„ æ­£åœ¨è·å–RSSæ–‡ç« ...")
    articles_data, analysis_text = fetch_rss_articles(rss_feeds, max_articles=5)
    print(f"âœ… æ–‡ç« è·å–å®Œæˆ")
    print(f"   æ–‡ç« åˆ†ç±»æ•°é‡: {len(articles_data)}")
    print(f"   æ–‡ç« ç±»åˆ«: {list(articles_data.keys())}")
    
    # 2. ä½¿ç”¨AIç”Ÿæˆè´¢ç»æ–°é—»æ‘˜è¦
    today_str = today.strftime("%Y-%m-%d")
    final_summary = ""
    
    try:
        print("ğŸ§  æ­£åœ¨ç”ŸæˆAIè´¢ç»æ‘˜è¦...")
        ai_summary = summarize(analysis_text)
        print(f"âœ… AIæ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(ai_summary)}å­—ç¬¦")
        final_summary = f"ğŸ“… **{today_str} è´¢ç»æ–°é—»æ‘˜è¦**\n\nâœï¸ **ä»Šæ—¥åˆ†ææ€»ç»“ï¼š**\n{ai_summary}\n\n---\n\n"
    except Exception as e:
        print(f"âŒ AIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        final_summary = f"ğŸ“… **{today_str} è´¢ç»æ–°é—»æ‘˜è¦**\n\nâœï¸ **ä»Šæ—¥åˆ†ææ€»ç»“ï¼š**\nAIæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè¯·æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯\n\n---\n\n"

    
    print("ğŸ“ æ­£åœ¨ç»„è£…æœ€ç»ˆæ¶ˆæ¯...")
    for category, content in articles_data.items():
        if content.strip():
            print(f"   æ·»åŠ {category}ç±»æ–‡ç« ï¼Œé•¿åº¦: {len(content)}")
            final_summary += f"## {category}\n{content}\n\n"
    
    # 3. è·å–access_token
    access_token = get_access_token()
    if not access_token:
        print("âŒ è·å–access_tokenå¤±è´¥")
        return
    
    # 4. ç”ŸæˆHTMLæ–‡ä»¶ï¼Œä½¿ç”¨å®Œæ•´å†…å®¹
    summary_html_path = generate_summary_html(final_summary)  # ä½¿ç”¨å®Œæ•´å†…å®¹
    
    # 5. å‘é€æ¶ˆæ¯åˆ°å¾®ä¿¡
    response = send_news_to_wechat(access_token, final_summary, summary_html_path)
    
    if response.get("errcode") == 0:
        print(f"âœ… {time_period}è´¢ç»æ–°é—»æ¨é€æˆåŠŸ")
    else:
        print(f"âŒ {time_period}è´¢ç»æ–°é—»æ¨é€å¤±è´¥: {response}")

if __name__ == '__main__':
    news_report()