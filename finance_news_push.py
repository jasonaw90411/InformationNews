# å®‰è£…ä¾èµ– pip3 install requests html5lib bs4 schedule
import os
import requests
import json
from openai import OpenAI
import feedparser
from newspaper import Article
from datetime import datetime
import time
import pytz

# ä»ç¯å¢ƒå˜é‡è·å–å¾®ä¿¡å…¬ä¼—å·é…ç½®
appID = os.environ.get("APP_ID")
appSecret = os.environ.get("APP_SECRET")
openId = os.environ.get("OPEN_ID")
template_id = os.environ.get("TEMPLATE_ID")

# é€‰æ‹©ä½¿ç”¨çš„AIæœåŠ¡ (deepseek æˆ– alimind)
ai_service = os.environ.get("AI_SERVICE", "deepseek")

if ai_service == "deepseek":
    # DeepSeek API Key
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æœªè®¾ç½®!")
    api_base_url = "https://api.deepseek.com/v1"
    model_name = "deepseek-chat"
elif ai_service == "alimind":
    # é˜¿é‡Œåƒæ–‡APIé…ç½®
    api_key = os.environ.get("ALI_MIND_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ ALI_MIND_API_KEY æœªè®¾ç½®!")
    api_base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # é˜¿é‡Œåƒæ–‡å…¼å®¹OpenAIæ¥å£çš„åœ°å€
    model_name = "qwen-turbo"  # é˜¿é‡Œåƒæ–‡æ¨¡å‹åç§°
else:
    raise ValueError(f"ä¸æ”¯æŒçš„AIæœåŠ¡ç±»å‹: {ai_service}")

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
openai_client = OpenAI(api_key=api_key, base_url=api_base_url)
print(f"ä½¿ç”¨AIæœåŠ¡: {ai_service}, æ¨¡å‹: {model_name}")

# RSSæºåœ°å€åˆ—è¡¨
rss_feeds = {
    "ğŸ’² åå°”è¡—è§é—»":{
        "åå°”è¡—è§é—»":"https://dedicated.wallstreetcn.com/rss.xml",      
    },
    "ğŸ’» 36æ°ª":{
        "36æ°ª":"https://36kr.com/feed",   
        },
    "ğŸ‡¨ğŸ‡³ ä¸­å›½ç»æµ": {
        "é¦™æ¸¯ç¶“æ¿Ÿæ—¥å ±":"https://www.hket.com/rss/china",
        "ä¸œæ–¹è´¢å¯Œ":"http://rss.eastmoney.com/rss_partener.xml",
        "ç™¾åº¦è‚¡ç¥¨ç„¦ç‚¹":"http://news.baidu.com/n?cmd=1&class=stock&tn=rss&sub=0",
        "ä¸­æ–°ç½‘":"https://www.chinanews.com.cn/rss/finance.xml",
        "å›½å®¶ç»Ÿè®¡å±€-æœ€æ–°å‘å¸ƒ":"https://www.stats.gov.cn/sj/zxfb/rss.xml",
    },
      "ğŸ‡ºğŸ‡¸ ç¾å›½ç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/WSJcomUSBusiness",
        "åå°”è¡—æ—¥æŠ¥ - å¸‚åœº":"https://feeds.content.dowjones.io/public/rss/RSSMarketsMain",
        "MarketWatchç¾è‚¡": "https://www.marketwatch.com/rss/topstories",
        "ZeroHedgeåå°”è¡—æ–°é—»": "https://feeds.feedburner.com/zerohedge/feed",
        "ETF Trends": "https://www.etftrends.com/feed/",
    },
    "ğŸŒ ä¸–ç•Œç»æµ": {
        "åå°”è¡—æ—¥æŠ¥ - ç»æµ":"https://feeds.content.dowjones.io/public/rss/socialeconomyfeed",
        "BBCå…¨çƒç»æµ": "http://feeds.bbci.co.uk/news/business/rss.xml",
    },
}

# è·å–åŒ—äº¬æ—¶é—´
def today_date():
    return datetime.now(pytz.timezone("Asia/Shanghai")).date()

# è·å–å½“å‰æ—¶é—´æ®µæ ‡è¯†ï¼ˆä¸Šåˆ/ä¸‹åˆï¼‰
def get_time_period():
    hour = datetime.now(pytz.timezone("Asia/Shanghai")).hour
    if 6 <= hour < 12:
        return "ä¸Šåˆ"
    elif 12 <= hour < 18:
        return "ä¸‹åˆ"
    else:
        return "æ™šé—´"

# çˆ¬å–ç½‘é¡µæ­£æ–‡ (ç”¨äº AI åˆ†æ)
def fetch_article_text(url):
    try:
        # ç§»é™¤çˆ¬å–æ–‡ç« å¼€å§‹çš„æ‰“å°
        article = Article(url)
        article.download()
        article.parse()
        text = article.text[:1500]  # é™åˆ¶é•¿åº¦ï¼Œé˜²æ­¢è¶…å‡º API è¾“å…¥é™åˆ¶
        if not text:
            # ç§»é™¤å†…å®¹ä¸ºç©ºçš„æ‰“å°
            pass
        return text
    except Exception as e:
        # ç§»é™¤çˆ¬å–å¤±è´¥çš„æ‰“å°
        return "ï¼ˆæœªèƒ½è·å–æ–‡ç« æ­£æ–‡ï¼‰"

# æ·»åŠ  User-Agent å¤´
def fetch_feed_with_headers(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    return feedparser.parse(url, request_headers=headers)

# è‡ªåŠ¨é‡è¯•è·å– RSS
def fetch_feed_with_retry(url, retries=3, delay=5):
    for i in range(retries):
        try:
            feed = fetch_feed_with_headers(url)
            if feed and hasattr(feed, 'entries') and len(feed.entries) > 0:
                return feed
        except Exception as e:
            # ç§»é™¤å¤±è´¥é‡è¯•çš„æ‰“å°
            time.sleep(delay)
    # ç§»é™¤æœ€ç»ˆå¤±è´¥çš„æ‰“å°
    return None

# è·å–RSSå†…å®¹ï¼ˆçˆ¬å–æ­£æ–‡ç”¨äºåˆ†æï¼‰
def fetch_rss_articles(rss_feeds, max_articles=5):
    news_data = {}
    analysis_text = ""  # ç”¨äºAIåˆ†æçš„æ­£æ–‡å†…å®¹

    for category, sources in rss_feeds.items():
        category_content = ""
        for source, url in sources.items():
            # ç§»é™¤RSSè·å–å¼€å§‹çš„æ‰“å°
            feed = fetch_feed_with_retry(url)
            if not feed:
                # ç§»é™¤RSSè·å–å¤±è´¥çš„æ‰“å°
                continue
            # ç§»é™¤RSSè·å–æˆåŠŸçš„æ‰“å°

            articles = []  # æ¯ä¸ªsourceéƒ½éœ€è¦é‡æ–°åˆå§‹åŒ–åˆ—è¡¨
            for entry in feed.entries[:5]:
                title = entry.get('title', 'æ— æ ‡é¢˜')
                link = entry.get('link', '') or entry.get('guid', '')
                if not link:
                    # ç§»é™¤æ— é“¾æ¥è·³è¿‡çš„æ‰“å°
                    continue

                # çˆ¬å–æ­£æ–‡ç”¨äºåˆ†æ
                article_text = fetch_article_text(link)
                analysis_text += f"ã€{title}ã€‘\n{article_text}\n\n"

                # ç§»é™¤å•æ¡æ–°é—»è·å–æˆåŠŸçš„æ‰“å°
                articles.append(f"[{title}]({link})")

            if articles:
                category_content += f"### {source}\n" + "\n".join(articles) + "\n\n"

        news_data[category] = category_content

    return news_data, analysis_text

# AI ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆåŸºäºçˆ¬å–çš„æ­£æ–‡ï¼‰
# ç”Ÿæˆå®Œæ•´æ–°é—»æ‘˜è¦HTMLæ–‡ä»¶
def generate_summary_html(summary_text):
    # ä½¿ç”¨å›ºå®šæ–‡ä»¶ååœ¨åŒå±‚çº§ç”ŸæˆHTMLï¼Œä¾¿äºGitHub Pagesè®¿é—®
    html_filename = 'finance_summary.html'
    
    # ç”Ÿæˆå½“å‰æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå•ç‹¬è®¡ç®—ï¼Œé¿å…f-stringä¸­çš„è¯­æ³•é—®é¢˜ï¼‰
    current_time = datetime.now(pytz.timezone("Asia/Shanghai")).strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    # è½¬ä¹‰æ¢è¡Œç¬¦ä¸ºHTML<br>æ ‡ç­¾
    formatted_summary = summary_text.replace('\n', '<br>')
    
    # ç”ŸæˆHTMLå†…å®¹
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="format-detection" content="telephone=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <title>è´¢ç»æ–°é—»æ‘˜è¦</title>
        <style>
            /* å®‰å…¨åŒºåŸŸæ ·å¼é‡ç½® */
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            
            /* åŸºç¡€æ ·å¼ */
            body {{
                font-family: -apple-system, BlinkMacSystemFont, 'PingFang SC', 'Microsoft YaHei', Arial, sans-serif;
                line-height: 1.7;
                color: #333;
                max-width: 100%;
                margin: 0;
                padding: 0;
                background-color: #f8f8f8;
                -webkit-text-size-adjust: 100%;
                -webkit-tap-highlight-color: transparent;
            }}
            
            /* å®¹å™¨æ ·å¼ */
            .container {{
                max-width: 800px;
                margin: 0 auto;
                padding: 20px 15px;
                background-color: #fff;
                min-height: 100vh;
            }}
            
            /* æ ‡é¢˜æ ·å¼ */
            h1, h2, h3 {{
                color: #2c3e50;
                margin: 15px 0 10px 0;
                line-height: 1.4;
            }}
            
            h1 {{ font-size: 22px; padding-bottom: 10px; border-bottom: 1px solid #eee; }}
            h2 {{ font-size: 20px; }}
            h3 {{ font-size: 18px; }}
            
            /* å†…å®¹æ ·å¼ */
            .summary-content {{ background: white; padding: 0; }}
            .summary-meta {{
                color: #666;
                font-size: 14px;
                margin-bottom: 15px;
                padding-bottom: 15px;
                border-bottom: 1px solid #eee;
            }}
            
            .summary-body {{
                font-size: 16px;
                color: #333;
            }}
            
            /* æ®µè½æ ·å¼ */
            .summary-body > div {{
                margin-bottom: 15px;
            }}
            
            /* å“åº”å¼è®¾è®¡ */
            @media (max-width: 480px) {{
                .container {{
                    padding: 15px 12px;
                }}
                
                h1 {{ font-size: 20px; }}
                h2 {{ font-size: 18px; }}
                h3 {{ font-size: 16px; }}
                
                .summary-body {{
                    font-size: 15px;
                }}
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="summary-content">
                <h1>è´¢ç»æ–°é—»æ‘˜è¦</h1>
                <div class="summary-meta">ç”Ÿæˆæ—¶é—´: {current_time}</div>
                <div class="summary-body">
                    {formatted_summary}
                </div>
            </div>
        </div>
        
        <script>
            // ç®€å•çš„å…¼å®¹æ€§è„šæœ¬
            document.addEventListener('DOMContentLoaded', function() {{
                // å¤„ç†iOS Safariä¸Šçš„æ»šåŠ¨é—®é¢˜
                document.body.style.webkitOverflowScrolling = 'touch';
            }});
        </script>
    </body>
    </html>
    """
    
    # å†™å…¥æ–‡ä»¶
    with open(html_filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    # è¿”å›æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
    return html_filename

# AI ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆåŸºäºçˆ¬å–çš„æ­£æ–‡ï¼‰
def summarize(text):
    completion = openai_client.chat.completions.create(
        model=model_name, 
        messages=[
            {"role": "system", "content": """
             ä½ æ˜¯ä¸€åä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ–°é—»å†…å®¹ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡ï¼š
             1. æå–æ–°é—»ä¸­æ¶‰åŠçš„ä¸»è¦è¡Œä¸šå’Œä¸»é¢˜ï¼Œæ‰¾å‡ºè¿‘1å¤©æ¶¨å¹…æœ€é«˜çš„3ä¸ªè¡Œä¸šæˆ–ä¸»é¢˜ï¼Œä»¥åŠè¿‘3å¤©æ¶¨å¹…è¾ƒé«˜ä¸”æ­¤å‰2å‘¨è¡¨ç°å¹³æ·¡çš„3ä¸ªè¡Œä¸š/ä¸»é¢˜ã€‚ï¼ˆå¦‚æ–°é—»æœªæä¾›å…·ä½“æ¶¨å¹…ï¼Œè¯·ç»“åˆæè¿°å’Œå¸‚åœºæƒ…ç»ªæ¨æµ‹çƒ­ç‚¹ï¼‰
             2. é’ˆå¯¹æ¯ä¸ªçƒ­ç‚¹ï¼Œè¾“å‡ºï¼š
                - å‚¬åŒ–å‰‚ï¼šåˆ†æè¿‘æœŸä¸Šæ¶¨çš„å¯èƒ½åŸå› ï¼ˆæ”¿ç­–ã€æ•°æ®ã€äº‹ä»¶ã€æƒ…ç»ªç­‰ï¼‰ã€‚
                - å¤ç›˜ï¼šæ¢³ç†è¿‡å»3ä¸ªæœˆè¯¥è¡Œä¸š/ä¸»é¢˜çš„æ ¸å¿ƒé€»è¾‘ã€å…³é”®åŠ¨æ€ä¸é˜¶æ®µæ€§èµ°åŠ¿ã€‚
                - å±•æœ›ï¼šåˆ¤æ–­è¯¥çƒ­ç‚¹æ˜¯çŸ­æœŸç‚’ä½œè¿˜æ˜¯æœ‰æŒç»­è¡Œæƒ…æ½œåŠ›ã€‚
             3. å°†ä»¥ä¸Šåˆ†ææ•´åˆä¸ºä¸€ç¯‡1500å­—ä»¥å†…çš„è´¢ç»çƒ­ç‚¹æ‘˜è¦ï¼Œé€»è¾‘æ¸…æ™°ã€é‡ç‚¹çªå‡ºï¼Œé€‚åˆä¸“ä¸šæŠ•èµ„è€…é˜…è¯»ã€‚
             """},
            {"role": "user", "content": text}
        ]
    )
    return completion.choices[0].message.content.strip()

# è·å–å¾®ä¿¡å…¬ä¼—å·access_token
def get_access_token():
    # è·å–access tokençš„url
    url = 'https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&appid={}&secret={}' \
        .format(appID.strip(), appSecret.strip())
    response = requests.get(url).json()
    # ç§»é™¤å“åº”æ‰“å°
    access_token = response.get('access_token')
    return access_token

# å‘é€è´¢ç»æ–°é—»åˆ°å¾®ä¿¡
def send_news_to_wechat(access_token, news_content, summary_html_path):
    # åˆ é™¤è°ƒè¯•ä¿¡æ¯
    
    # touser å°±æ˜¯ openID
    # template_id å°±æ˜¯æ¨¡æ¿ID
    # url å°±æ˜¯ç‚¹å‡»æ¨¡æ¿è·³è½¬çš„url
    # dataæŒ‰æ¨¡æ¿æ ¼å¼ç»„ç»‡

    today = datetime.now(pytz.timezone("Asia/Shanghai"))
    today_str = today.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    time_period = get_time_period()
    
    # ä¼˜åŒ–å†…å®¹å¤„ç† - å¤„ç†å¯èƒ½å¯¼è‡´æ˜¾ç¤ºé—®é¢˜çš„å…ƒç´ 
    if isinstance(news_content, str):
        # 1. ç§»é™¤æˆ–æ›¿æ¢ç‰¹æ®Šå­—ç¬¦å’Œè¡¨æƒ…ç¬¦å·
        # åˆ›å»ºä¸€ä¸ªæ¸…ç†åçš„ç‰ˆæœ¬
        clean_content = news_content
        
        # æ›¿æ¢å¸¸è§è¡¨æƒ…ç¬¦å·
        emoji_replacements = {
            'ğŸ“…': '[æ—¥æœŸ]',
            'âœï¸': '[åˆ†æ]',
            'ğŸ’²': '',
            'ğŸ’»': '',
            'ğŸ‡¨ğŸ‡³': '[ä¸­å›½]',
            'ğŸ‡ºğŸ‡¸': '[ç¾å›½]',
            'ğŸŒ': '[ä¸–ç•Œ]',
            'âœ…': '',
            'ğŸ¤–': '[AI]',
            'ğŸ“': '',
            'ğŸ“¤': ''
        }
        
        for emoji, replacement in emoji_replacements.items():
            clean_content = clean_content.replace(emoji, replacement)
        
        # 2. ç§»é™¤æˆ–ç®€åŒ–Markdownæ ¼å¼
        # ç§»é™¤###å’Œ####æ ‡é¢˜æ ‡è®°
        clean_content = clean_content.replace('### ', '')
        clean_content = clean_content.replace('#### ', '')
        
        # 3. å¤„ç†æ¢è¡Œç¬¦ï¼Œç¡®ä¿æ­£ç¡®æ˜¾ç¤º
        # ç¡®ä¿ä½¿ç”¨æ ‡å‡†æ¢è¡Œç¬¦
        clean_content = clean_content.replace('\r\n', '\n')
        
        # 4. å¤„ç†é•¿åº¦é™åˆ¶ - ç§»é™¤é™åˆ¶ï¼Œå±•ç¤ºå®Œæ•´å†…å®¹
        core_content = clean_content
    else:
        core_content = "å†…å®¹ç”Ÿæˆå¤±è´¥"

    # ä½¿ç”¨GitHub Pages URLä½œä¸ºè·³è½¬é“¾æ¥
    # æ³¨æ„ï¼šéœ€è¦æ›¿æ¢ä¸ºæ‚¨å®é™…çš„GitHub Pages URL
    # æ ¼å¼ä¸º: https://[username].github.io/[repository]/finance_summary.html
    github_pages_url = "https://jasonaw90411.github.io/InformationNews/finance_summary.html"
    
    # åœ¨GitHub Actionsç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨GITHUB_REPOSITORYç¯å¢ƒå˜é‡æ¥æ„å»ºURL
    github_repo = os.environ.get('GITHUB_REPOSITORY', '')
    if github_repo:
        # github_repo æ ¼å¼é€šå¸¸ä¸º "username/repository"
        parts = github_repo.split('/')
        if len(parts) == 2:
            github_pages_url = f"https://{parts[0]}.github.io/{parts[1]}/finance_summary.html"
    
    body = {
        "touser": openId.strip(),
        "template_id": template_id.strip(),
        "url": github_pages_url,  # ä½¿ç”¨GitHub Pages URLä½œä¸ºè·³è½¬é“¾æ¥
        "data": {
            "date": {
                "value": f"{today_str} - {time_period}æ¨é€"
            },
            "content": {
                "value": core_content
            },
            "remark": {
                "value": f"{time_period}è´¢ç»ç®€æŠ¥"  
            }
        }
    }
    
    
    url = 'https://api.weixin.qq.com/cgi-bin/message/template/send?access_token={}'.format(access_token)
    response = requests.post(url, json.dumps(body))
    # ç§»é™¤å“åº”çŠ¶æ€æ‰“å°
    return response.json()

# ä¸»å‡½æ•°
def news_report():
    print("===== å¼€å§‹æ–°é—»æŠ¥å‘Šæµç¨‹ =====")
    
    # 1. è·å–RSSæ–‡ç« 
    print("ğŸ”„ æ­£åœ¨è·å–RSSæ–‡ç« ...")
    articles_data, analysis_text = fetch_rss_articles(rss_feeds, max_articles=5)
    print(f"âœ… æ–‡ç« è·å–å®Œæˆï¼Œåˆ†ææ–‡æœ¬é•¿åº¦: {len(analysis_text) if analysis_text else 0}")
    print(f"   æ–‡ç« åˆ†ç±»æ•°é‡: {len(articles_data)}")
    print(f"   æ–‡ç« ç±»åˆ«: {list(articles_data.keys())}")
    
    # 2. AIç”Ÿæˆæ‘˜è¦
    print("ğŸ¤– æ­£åœ¨ç”ŸæˆAIæ‘˜è¦...")
    summary = summarize(analysis_text)
    print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary) if summary else 0}")
    print(f"   æ‘˜è¦å‰50å­—ç¬¦: {summary[:50] if summary else 'æ— å†…å®¹'}")
    
    # 3. ç”Ÿæˆæœ€ç»ˆæ¶ˆæ¯
    today_str = today_date().strftime("%Y-%m-%d")
    time_period = get_time_period()
    final_summary = f"ğŸ“… {today_str} {time_period}è´¢ç»æ–°é—»æ‘˜è¦\n\nâœï¸ {time_period}åˆ†ææ€»ç»“ï¼š\n{summary}\n\n---\n\n"
    
    print("ğŸ“ æ­£åœ¨ç»„è£…æœ€ç»ˆæ¶ˆæ¯...")
    for category, content in articles_data.items():
        if content.strip():
            print(f"   æ·»åŠ {category}ç±»æ–‡ç« ï¼Œé•¿åº¦: {len(content)}")
            final_summary += f"## {category}\n{content}\n\n"
    
    # 4. è·å–access_token
    access_token = get_access_token()
    if not access_token:
        print("âŒ è·å–access_tokenå¤±è´¥")
        return
    
    # 5. ç”Ÿæˆæ‘˜è¦HTMLæ–‡ä»¶ï¼Œç”¨äºç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…
    summary_html_path = generate_summary_html(summary)  # åªä¿å­˜æ‘˜è¦éƒ¨åˆ†
    
    # 6. å‘é€æ¶ˆæ¯åˆ°å¾®ä¿¡
    response = send_news_to_wechat(access_token, final_summary, summary_html_path)
    
    if response.get("errcode") == 0:
        print(f"âœ… {time_period}è´¢ç»æ–°é—»æ¨é€æˆåŠŸ")
    else:
        print(f"âŒ {time_period}è´¢ç»æ–°é—»æ¨é€å¤±è´¥: {response}")

if __name__ == '__main__':
    news_report()